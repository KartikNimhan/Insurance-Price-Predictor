{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Tracking URI: file:///d:/My%20projects/Medical%20Insurane%20Predictor/mlruns\n",
      "MLflow Username: None\n",
      "MLflow Password: None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "print(\"MLflow Tracking URI:\", mlflow.get_tracking_uri())\n",
    "print(\"MLflow Username:\", os.getenv(\"MLFLOW_TRACKING_USERNAME\"))\n",
    "print(\"MLflow Password:\", os.getenv(\"MLFLOW_TRACKING_PASSWORD\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from src.mlProject.logger import logging\n",
    "from src.mlProject.exception import CustomException\n",
    "import sys\n",
    "\n",
    "# Paths\n",
    "raw_data_path = os.path.join(\"D:/My projects/Medical Insurane Predictor/data/raw_data\", \"insurance.csv\")\n",
    "processed_data_path = os.path.join(\"D:/My projects/Medical Insurane Predictor/data/Processed_data\", \"processed_data.csv\")\n",
    "\n",
    "# Ensure the directory for processed data exists\n",
    "os.makedirs(os.path.dirname(processed_data_path), exist_ok=True)\n",
    "\n",
    "def preprocess_data():\n",
    "    try:\n",
    "        # Load the dataset\n",
    "        df = pd.read_csv(raw_data_path)\n",
    "\n",
    "        # Log the data shape\n",
    "        logging.info(f\"Loaded dataset with shape: {df.shape}\")\n",
    "\n",
    "        # Check for any missing values\n",
    "        if df.isnull().sum().any():\n",
    "            logging.warning(f\"Missing values found in the dataset. Filling with mean or mode.\")\n",
    "            # Handle missing values (you can fill with mean or mode depending on the column type)\n",
    "            df.fillna(df.mean(), inplace=True)  # For numerical columns\n",
    "            df.fillna(df.mode().iloc[0], inplace=True)  # For categorical columns\n",
    "\n",
    "        # Encoding categorical columns using LabelEncoder\n",
    "        label_encoder = LabelEncoder()\n",
    "\n",
    "        # Assuming 'sex', 'smoker', and 'region' are categorical\n",
    "        df['sex'] = label_encoder.fit_transform(df['sex'])\n",
    "        df['smoker'] = label_encoder.fit_transform(df['smoker'])\n",
    "        df['region'] = label_encoder.fit_transform(df['region'])\n",
    "\n",
    "        # Log the first few rows of the processed data\n",
    "        logging.info(f\"Processed data:\\n{df.head()}\")\n",
    "\n",
    "        # Save the cleaned data to the processed folder\n",
    "        df.to_csv(processed_data_path, index=False)\n",
    "        logging.info(f\"Data preprocessed and saved to {processed_data_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred during data preprocessing: {str(e)}\")\n",
    "        raise CustomException(str(e), sys)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preprocess_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
